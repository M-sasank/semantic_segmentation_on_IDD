{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ss6QWIEIi_lh"
   },
   "source": [
    "# Semantic Segmentation using Eff-UNet on IDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uvYKcvbGi_li"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "import os,sys,ntpath,fnmatch,shutil,cv2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from numpy import asarray,zeros,moveaxis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "import os,sys,ntpath,fnmatch,shutil,cv2\n",
    "import joblib,time,os.path,itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csc_matrix\n",
    "from sklearn.metrics import *\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm_notebook,tqdm\n",
    "from keras.models import load_model \n",
    "import gc\n",
    "np.random.seed(0)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "clear_output()\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from time import time\n",
    "import segmentation_models as sm\n",
    "import tensorflow.keras\n",
    "tensorflow.keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root path to save the trained model\n",
    "model_root = \"/media/ram/338f6363-03b7-4ad7-a2be-40c31f59dee4/20230418_backup/ram/Students/B.Tech_2020/sasank/trained_models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of the raw dataset, freshly extracted from the zip file\n",
    "root = \"/media/ram/338f6363-03b7-4ad7-a2be-40c31f59dee4/20230418_backup/ram/Students/B.Tech_2020/sasank/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organising the dataset into a structured way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/ram/338f6363-03b7-4ad7-a2be-40c31f59dee4/20230418_backup/ram/Students/B.Tech_2020/sasank/IDD_Segmentation\n",
      "/bin/bash: -c: line 0: syntax error near unexpected token `)'\n",
      "/bin/bash: -c: line 0: `python \"/media/ram/338f6363-03b7-4ad7-a2be-40c31f59dee4/20230418_backup/ram/Students/B.Tech_2020/sasank/Code/Training/lab113/public-code/preperation/createLabels.py\") --datadir \"/media/ram/338f6363-03b7-4ad7-a2be-40c31f59dee4/20230418_backup/ram/Students/B.Tech_2020/sasank/IDD_Segmentation\" --id-type level1Id --color True --num-workers 2'\n"
     ]
    }
   ],
   "source": [
    "image_set = 1 # since training only first part of IDD\n",
    "string_path = os.path.join(root ,\"IDD_Segmentation\")\n",
    "print(string_path)\n",
    "\n",
    "    \n",
    "# Rename all file with file's folder_name as prefix\n",
    "# parentFolder=string_path\n",
    "# for dirName, subdirs, fileList in os.walk(parentFolder):    \n",
    "#     for filename in fileList:\n",
    "#         path = os.path.join(dirName, filename)\n",
    "#         os.rename(path,\"{}/{}_{}\".format(dirName,ntpath.basename(dirName),ntpath.basename(filename)))\n",
    "        \n",
    "# Label Mask generation for given image_set. \n",
    "# The code for conversion of json to labels is from the public-code repository maintained by IDD owners\n",
    "if image_set==1:\n",
    "    !python \"/media/ram/338f6363-03b7-4ad7-a2be-40c31f59dee4/20230418_backup/ram/Students/B.Tech_2020/sasank/Code/Training/lab113/public-code/preperation/createLabels.py\") --datadir \"/media/ram/338f6363-03b7-4ad7-a2be-40c31f59dee4/20230418_backup/ram/Students/B.Tech_2020/sasank/IDD_Segmentation\" --id-type level1Id --color True --num-workers 2\n",
    "# elif image_set==2:\n",
    "#     !python \"E:\\Anime\\public-code\\preperation\\createLabels.py\" --datadir \"C:\\Users\\sasan\\OneDrive\\Desktop\\FYP\\idd-segmentation\\IDD_Segmentation\" --id-type level3Id --color True --num-workers 2\n",
    "\n",
    "# clear output Screen\n",
    "clear_output(wait=True)\n",
    "\n",
    "# Re-Organize files into a single folder. So that training is easier\n",
    "def Organize_Labels(id_level):\n",
    "    pattern,partial_dir='*level1Ids.png',\"_label_level1\"\n",
    "    \n",
    "    # Group files to corresponding train or val set\n",
    "    def Group_Files(dirPath, pattern):\n",
    "        for parentDir, dirnames, filenames in os.walk(dirPath):\n",
    "            for filename in fnmatch.filter(filenames, pattern):\n",
    "                shutil.move(os.path.join(parentDir, filename), r\"{}{}/{}\".format(dirPath,partial_dir,filename))\n",
    "        return True\n",
    "    \n",
    "    # Make new Directory to Organize train Files\n",
    "    os.mkdir(string_path+\"/gtFine/train\"+partial_dir)\n",
    "    return_val = Group_Files(string_path+'/gtFine/train', pattern)\n",
    "    \n",
    "    # Make new Directory to Organize val Files\n",
    "    os.mkdir(string_path+\"/gtFine/val\"+partial_dir)\n",
    "    return_val = Group_Files(string_path+'/gtFine/val', pattern)\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Invoke Organize_Labels for Level1\n",
    "# indicator=Organize_Labels(id_level=1)\n",
    "\n",
    "# # Function to remove unwanted Files and Folders after mask generation\n",
    "# def RemoveUnwantedFiles(dirPath, pattern):\n",
    "#     for parentDir, dirnames, filenames in os.walk(dirPath):\n",
    "#         for filename in fnmatch.filter(filenames, pattern):\n",
    "#             shutil.move(os.path.join(parentDir, filename), dirPath+\"/\"+filename)\n",
    "#         if len(os.listdir(parentDir)) == 0:\n",
    "#             os.rmdir(parentDir)\n",
    "#     return  True\n",
    "\n",
    "# # Invoke RemoveUnwantedFiles for Image_set1\n",
    "# if image_set==1:\n",
    "#     indicator = RemoveUnwantedFiles(string_path+'/leftImg8bit/train', \"*.png\")\n",
    "#     indicator = RemoveUnwantedFiles(string_path+'/leftImg8bit/val', \"*.png\")\n",
    "#     indicator = RemoveUnwantedFiles(string_path+'/leftImg8bit/test', \"*.png\")\n",
    "\n",
    "# # Invoke RemoveUnwantedFiles for Image_set2\n",
    "# elif image_set==2:\n",
    "#     indicator = RemoveUnwantedFiles(string_path+'/leftImg8bit/train', \"*.jpg\")\n",
    "#     indicator = RemoveUnwantedFiles(string_path+'/leftImg8bit/val', \"*.jpg\")\n",
    "#     indicator = RemoveUnwantedFiles(string_path+'/leftImg8bit/test', \"*.jpg\")\n",
    "# print(\"Label generation successful for Image_Set part{} Done\".format(image_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6993 6993 981 981\n"
     ]
    }
   ],
   "source": [
    "train_img_files1=sorted(os.listdir(root+'IDD_Segmentation/leftImg8bit/train'))\n",
    "train_label_files1=sorted(os.listdir(root+'IDD_Segmentation/gtFine/train_label_level3'))\n",
    "val_img_files1=sorted(os.listdir(root+'IDD_Segmentation/leftImg8bit/val'))\n",
    "val_label_files1=sorted(os.listdir(root+'IDD_Segmentation/gtFine/val_label_level3'))\n",
    "print(len(train_img_files1), len(train_label_files1), len(val_img_files1), len(val_label_files1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image data preprocessing\n",
    "- Resizing image data to 224x480x3\n",
    "- Normalizing pixel values\n",
    "- Save the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# import cv2\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def Prepare_Image_and_Save(path, name, img_files):\n",
    "#     height, width = 224, 480\n",
    "#     image = []\n",
    "#     for j in range(len(path)):\n",
    "#         for i in tqdm(range(len(img_files[j]))):\n",
    "#             img = cv2.imread(path[j] + img_files[j][i])\n",
    "#             img = cv2.resize(img, (width, height))\n",
    "#             img = np.float32(img) / 255\n",
    "#             image.append(img)\n",
    "#     print(len(image))\n",
    "#     joblib.dump(image, name)\n",
    "#     return True\n",
    "\n",
    "# path1 = [root+'IDD_Segmentation/leftImg8bit/train/']\n",
    "# path2 = [root+'IDD_Segmentation/leftImg8bit/val/']\n",
    "# train_img_files1=sorted(os.listdir(root+'IDD_Segmentation/leftImg8bit/train'))\n",
    "# train_label_files1=sorted(os.listdir(root+'IDD_Segmentation/gtFine/train_label_level3'))\n",
    "# val_img_files1=sorted(os.listdir(root+'IDD_Segmentation/leftImg8bit/val'))\n",
    "# val_label_files1=sorted(os.listdir(root+'IDD_Segmentation/gtFine/val_label_level3'))\n",
    "\n",
    "# img_files1,img_files2 = [train_img_files1],[val_img_files1]\n",
    "\n",
    "# Indicator1 = Prepare_Image_and_Save(path1,root+'IDD_Segmentation/prep_train_img_files_save',img_files1)\n",
    "# Indicator2 = Prepare_Image_and_Save(path2,root+'IDD_Segmentation/prep_val_img_files_save',img_files2)\n",
    "# if Indicator1 and Indicator2: print(\"Data Preparation of Images Successful Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label data preprocessing\n",
    "- Resizing mask data to 224x480x26\n",
    "- Performing one hot ecoding on mask\n",
    "- Save the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.sparse import csc_matrix\n",
    "# def Prepare_Label_and_Save(path, n_classes, name):\n",
    "#     sparse_list = []\n",
    "#     for k in range(len(path)):\n",
    "#         files = sorted(os.listdir(path[k]))\n",
    "#         height, width, n_classes = 224, 480, n_classes\n",
    "#         for j in tqdm(range(len(files))):\n",
    "#             label = np.zeros((n_classes, height, width), dtype=np.uint8)\n",
    "#             img = cv2.imread(path[k] + \"/\" + files[j], cv2.IMREAD_GRAYSCALE)\n",
    "#             img1 = cv2.resize(img, (width, height))\n",
    "#             for i in range(n_classes):\n",
    "#                 label[i, :, :] = (img1 == i).astype(np.uint8)\n",
    "#             sp_list = []\n",
    "#             for i in range(label.shape[0]):\n",
    "#                 sp_list.append(csc_matrix(label[i]))\n",
    "#             sparse_list.append(sp_list)\n",
    "#     joblib.dump(sparse_list, name)\n",
    "#     return True\n",
    "\n",
    "\n",
    "# path1 = [root+'IDD_Segmentation/gtFine/train_label_level3']\n",
    "# path2 = [root+'IDD_Segmentation/gtFine/val_label_level3']\n",
    "\n",
    "# img_files1,img_files2 = [train_img_files1],[val_img_files1]\n",
    "# Indicator=Prepare_Label_and_Save(path1,26,root+\"IDD_Segmentation/prep_train_label_files_save1\")\n",
    "# Indicator=Prepare_Label_and_Save(path2,26,root+\"IDD_Segmentation/prep_val_label_files_save1\")\n",
    "# if Indicator1 and Indicator2: print(\"Data Preparation of Labels Successful Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from os import path\n",
    "# from sklearn.utils import shuffle\n",
    "# import gc\n",
    "\n",
    "# def Shuffle_Data(root=root+\"IDD_Segmentation/\"):\n",
    "    \n",
    "#     # Shuffle Prepared Image Data\n",
    "#     path1, path3=root+\"data/prep_train_img_files_save\", root+\"prep_train_label_files_save1\"\n",
    "#     if path.exists(path1) and path.exists(path3):\n",
    "#         prep_train_img_files_save, prep_train_label_files_save=shuffle(joblib.load(path1),joblib.load(path3),random_state=0)\n",
    "#         Dump=joblib.dump(prep_train_img_files_save, path1), joblib.dump(prep_train_label_files_save, path3)\n",
    "#         del prep_train_img_files_save, prep_train_label_files_save\n",
    "#         Junk= gc.collect() \n",
    "\n",
    "#     # Shuffle Prepared Label Mask Data\n",
    "#     path2, path4=root+\"data/prep_val_img_files_save\", root+\"prep_val_label_files_save1\"\n",
    "#     if path.exists(path2) and path.exists(path4):\n",
    "#         prep_val_img_files_save, prep_val_label_files_save=shuffle(joblib.load(path2),joblib.load(path4),random_state=0)\n",
    "#         Dump=joblib.dump(prep_val_img_files_save, path2), joblib.dump(prep_val_label_files_save, path4)\n",
    "#         del prep_val_img_files_save, prep_val_label_files_save\n",
    "#         Junk= gc.collect()\n",
    "    \n",
    "#     return True\n",
    "\n",
    "# Indicator=Shuffle_Data()\n",
    "# if Indicator:print(\"Data Shuffle Successful Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import clear_output\n",
    "# def Train_Test_Split(root=root, split=0.8):\n",
    "#     total_no_samples=6993\n",
    "#     split_index=(int((total_no_samples*0.8)/32))*32\n",
    "    \n",
    "#     path1, path3= root+\"IDD_Segmentation/prep_train_img_files_save\", root+\"IDD_Segmentation/prep_train_label_files_save1\"\n",
    "#     prep_train_img_files_save, prep_train_label_files_save=joblib.load(path1), joblib.load(path3)\n",
    "    \n",
    "#     joblib.dump(prep_train_img_files_save[:split_index], root+\"IDD_Segmentation/prep_train_img_files_save_80\")\n",
    "#     joblib.dump(prep_train_label_files_save[:split_index], root+\"IDD_Segmentation/prep_train_label_files_save_80\")\n",
    "#     joblib.dump(prep_train_img_files_save[split_index:], root+\"IDD_Segmentation/prep_test_img_files_save_20\")\n",
    "#     joblib.dump(prep_train_label_files_save[split_index:], root+\"IDD_Segmentation/prep_test_label_files_save_20\")\n",
    "#     clear_output()\n",
    "#     return True\n",
    "\n",
    "# Indicator=Train_Test_Split()\n",
    "# if Indicator:print(\"Data Train_Test_Split Successful Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a train generator from prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "height,width,n_classes=224,480,26\n",
    "def image_generator_j(start,end,saved_data):\n",
    "    '''Function to get samples from saved data for each batch in each epoch'''\n",
    "    return np.array(saved_data[start:end])\n",
    "\n",
    "def label_generator_j(start,end,saved_data):\n",
    "    '''Function to get Mask from saved data for each batch in each epoch'''\n",
    "    slice_saved=saved_data[start:end]\n",
    "    ar=np.empty((len(slice_saved),n_classes,height,width), dtype=np.uint8)\n",
    "    for j in range(len(slice_saved)):\n",
    "        for i in range(n_classes):\n",
    "            ar[j][i]=slice_saved[j][i].todense()\n",
    "    ar = moveaxis(ar, 1, 3)\n",
    "    return ar\n",
    "\n",
    "def train_batch_generator_j(batch_size,epochs):\n",
    "    '''Function to yield train Images and Labels for each batch from saved Joblib file'''\n",
    "    global prep_train_img_files_save, prep_train_label_files_save\n",
    "    tr_L = len(prep_train_img_files_save)\n",
    "    num_tr=0\n",
    "    while num_tr<epochs*2 :\n",
    "        train_batch_start=0\n",
    "        train_batch_end = batch_size\n",
    "        while train_batch_start < tr_L:\n",
    "            train_limit = min(train_batch_end, tr_L)\n",
    "            batch_x = image_generator_j(train_batch_start,train_limit,prep_train_img_files_save) \n",
    "            batch_y = label_generator_j(train_batch_start,train_limit,prep_train_label_files_save)\n",
    "            yield (batch_x,batch_y)\n",
    "            train_batch_start += batch_size   \n",
    "            train_batch_end += batch_size\n",
    "        num_tr+=1\n",
    "\n",
    "def val_batch_generator_j(batch_size,epochs):\n",
    "    '''Function to yield validation Images and Labels for each batch from saved Joblib file'''\n",
    "    global prep_val_img_files_save, prep_val_label_files_save\n",
    "    val_L = len(prep_val_img_files_save)\n",
    "    num_val=0\n",
    "    while num_val<epochs*2:\n",
    "        val_batch_start=0\n",
    "        val_batch_end = batch_size\n",
    "        while val_batch_start < val_L:\n",
    "            val_limit = min(val_batch_end, val_L)\n",
    "            batch_valx = image_generator_j(val_batch_start,val_limit,prep_val_img_files_save)\n",
    "            batch_valy = label_generator_j(val_batch_start,val_limit,prep_val_label_files_save)\n",
    "            yield (batch_valx,batch_valy)\n",
    "            val_batch_start += batch_size   \n",
    "            val_batch_end += batch_size\n",
    "        num_val+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_generator, val_batch_generator = train_batch_generator_j, val_batch_generator_j\n",
    "prep_train_img_files_save, prep_train_label_files_save = joblib.load(root + \"IDD_Segmentation/prep_train_img_files_save_80\"), joblib.load(root + \"IDD_Segmentation/prep_train_label_files_save_80\")\n",
    "prep_val_img_files_save, prep_val_label_files_save = joblib.load(root + \"IDD_Segmentation/prep_val_img_files_save\"), joblib.load(root + \"IDD_Segmentation/prep_val_label_files_save1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_MIOU(y_val, y_pred):\n",
    "    class_iou ,n_classes=[],26\n",
    "    y_predi = np.argmax(y_pred, axis=3)\n",
    "    y_truei = np.argmax(y_val, axis=3)\n",
    "    for c in range(n_classes):\n",
    "        TP = np.sum((y_truei == c) & (y_predi == c))\n",
    "        FP = np.sum((y_truei != c) & (y_predi == c))\n",
    "        FN = np.sum((y_truei == c) & (y_predi != c)) \n",
    "        IoU = TP / float(TP + FP + FN)\n",
    "        if(float(TP + FP + FN) == 0):\n",
    "            IoU=TP/0.001\n",
    "        class_iou.append(IoU)\n",
    "    MIoU=sum(class_iou)/n_classes\n",
    "    return MIoU\n",
    "\n",
    "def miou( y_true, y_pred ) :\n",
    "    '''Funtion to Wraps a miou function into a TensorFlow op that executes when needed'''\n",
    "    score = tf.py_function( lambda y_true, y_pred : Calculate_MIOU( y_true, y_pred).astype('float32'),[y_true, y_pred],'float32')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Select_Model(weights_save_path=False):\n",
    "     \n",
    "    \"\"\"\n",
    "    Function to select a Model based on entered choice and load its respective Model weights for Successful Prediction \n",
    "    Input:  weights_save_path <Saved weights path or Boolean>\n",
    "    Returns: Model <Model Object>       \"\"\"\n",
    "\n",
    "    import ntpath,segmentation_models as sm\n",
    "    if weights_save_path==False:\n",
    "        print(\"Model Weights not provided. Exiting...\")\n",
    "    Model = sm.Unet('efficientnetb7',classes=26,input_shape=(224, 480,3),activation='softmax')\n",
    "    Model.load_weights(weights_save_path) if isinstance(weights_save_path, str) else Model.load_weights(\"\")\n",
    "    \n",
    "    # m=int(input(\"    1.Restnet_50+U-Net    2.Unet    3.DeeplabV3    4.Pspnet    5.Segnet >> Enter a number to Choose a Model:\\n>>> \"))\n",
    "    \n",
    "    # if m==1:\n",
    "        \n",
    "    #     if weights_save_path==False:weights_save_path=\"/content/drive/My Drive/IID_Files1/New_Model_logs_save/Unet_imgnet_resnet50_nlrr.hdf5\"\n",
    "    #     sent, sm_weight=ntpath.basename(weights_save_path)[12:],\"\"\n",
    "    #     for ch in sent:\n",
    "    #         if((ch >= 'a' and ch <= 'z') or (ch >= 'A' and ch <= 'Z')) or (ch >= '0' and ch <= '9'):\n",
    "    #             sm_weight+=ch\n",
    "    #         else: break\n",
    "        \n",
    "    #     Model = sm.Unet(sm_weight,classes=26,input_shape=(224, 480,3),activation='softmax')\n",
    "    #     Model.load_weights(weights_save_path) if isinstance(weights_save_path, str) else Model.load_weights(\"/content/drive/My Drive/IID_Files1/New_Model_logs_save/Unet_imgnet_resnet50_nlrr.hdf5\")\n",
    "    \n",
    "    # elif m==2:\n",
    "    #     Model = Unet_Segmentation((224, 480,3), 26)\n",
    "    #     Model.load_weights(weights_save_path) if isinstance(weights_save_path, str) else Model.load_weights(\"/content/drive/My Drive/IID_Files/Models_save/Unet.best.hdf5\")\n",
    "\n",
    "\n",
    "    # elif m==3:\n",
    "    #     Model = Deeplab_V3((224, 480,3), 26) \n",
    "    #     Model.load_weights(weights_save_path) if isinstance(weights_save_path, str) else Model.load_weights(\"/content/drive/My Drive/IID_Files/Models_save/Deeplab.best.hdf5\") \n",
    "    \n",
    "    # elif m==4:\n",
    "    #     Model=PSPNET((224, 480,3), 26)\n",
    "    #     Model.load_weights(weights_save_path) if isinstance(weights_save_path, str) else Model.load_weights(\"/content/drive/My Drive/IID_Files/Models_save/Pspnet.best.hdf5\") \n",
    "    \n",
    "    # elif m==5:\n",
    "    #     Model=Segnet_Segmentation((224,480,3), 26, 1)\n",
    "    #     Model.load_weights(weights_save_path) if isinstance(weights_save_path, str) else Model.load_weights(\"/content/drive/My Drive/IID_Files/Models_save/Segnet.best.hdf5\") \n",
    "\n",
    "    # else: raise Exception(\"Wrong Input>>Enter an Integer to choose a Model\")\n",
    "    \n",
    "    return Model\n",
    "\n",
    "def plot_segmentation(images, pred_labels, true_labels=[], plot_limit=5):\n",
    "\n",
    "    \"\"\" \n",
    "    Function to plot Sub-plot of Image, Label and Model Output after prediction is performed\n",
    "    Input  : (images, pred_labels, true_labels) <3dArray>, plot_limit <Int>\n",
    "    Return : None \"\"\" \n",
    "    \n",
    "    if (len(true_labels)==0):\n",
    "        for i in range(images.shape[0]):\n",
    "            if i==plot_limit:return \n",
    "            plt.figure(figsize=(14, 10))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(cv2.cvtColor(images[i],cv2.COLOR_BGR2RGB))\n",
    "            plt.ylabel('Image',fontsize=16)\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(color_code(pred_labels[i]))\n",
    "            plt.ylabel('Prediction',fontsize=16)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        for i in range(images.shape[0]):\n",
    "            if i==plot_limit:\n",
    "                print(\"  \"+\" ------------------ \"*8)\n",
    "                return \n",
    "            plt.figure(figsize=(28, 20))\n",
    "            plt.subplot(1,3,1)\n",
    "            plt.imshow(cv2.cvtColor(images[i],cv2.COLOR_BGR2RGB))\n",
    "            plt.ylabel('Image',fontsize=28)\n",
    "            plt.subplot(1,3,2)\n",
    "            plt.imshow(color_code(true_labels[i]))\n",
    "            plt.ylabel('Label',fontsize=28)\n",
    "            plt.subplot(1,3,3)\n",
    "            plt.imshow(color_code(pred_labels[i]))\n",
    "            plt.ylabel('Prediction',fontsize=28)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, normalize=True, title='Confusion matrix', cmap=plt.cm.Reds):\n",
    "\n",
    "    ''' Function to plot Confusion Matrix for given 2D_Matrix ''' \n",
    "\n",
    "    # ref: https://github.com/scikit-learn/scikit-learn/issues/12700\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    classes_dict={'road': 0, 'parking': 1, 'drivable fallback': 2, 'sidewalk': 3, 'rail track': 4, 'non-drivable fallback': 5, 'person': 6, 'animal': 7, 'rider': 8, 'motorcycle': 9, 'bicycle': 10, 'autorickshaw': 11, 'car': 12, 'truck': 13, 'bus': 14, 'caravan': 15, 'trailer': 16, 'train': 17, 'vehicle fallback': 18, 'curb': 19, 'wall': 20, 'fence': 21, 'guard rail': 22, 'billboard': 23, 'traffic sign': 24, 'traffic light': 25}\n",
    "    classes=list(list(classes_dict.keys()))\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title,fontsize=16)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90,fontsize=12)\n",
    "    plt.yticks(tick_marks, classes,fontsize=12)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label',fontsize=18)\n",
    "    plt.xlabel('Predicted label',fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def Print_result(Mean_MIoU, cf_matrix, Accuracy, true_labels_org, pred_labels_org, cr=True):\n",
    "\n",
    "    ''' Function to print all Final computed Results '''\n",
    "\n",
    "    # printing results\n",
    "    print(\"\\nPrinting Results:>>\\n\")\n",
    "    print('-----------------------')\n",
    "    print('|      MIOU Score     |')\n",
    "    print('-----------------------')\n",
    "    print('\\n   MIOU Score: {}\\n'.format(np.round(np.mean(Mean_MIoU),4)))\n",
    "\n",
    "    print('-----------------------')\n",
    "    print('|   Accuracy Score   |')\n",
    "    print('-----------------------')\n",
    "    print('\\n   Accuracy Score: {}\\n'.format(np.round(np.mean(Accuracy),4)))\n",
    "\n",
    "    print('-----------------------')\n",
    "    print('|  Confusion Matrix   |')\n",
    "    print('-----------------------')\n",
    "    plot_confusion_matrix(cf_matrix,normalize=True)\n",
    "    \n",
    "    if cr==True:\n",
    "        print('-------------------------')\n",
    "        print('| Classifiction Report  |')\n",
    "        print('-------------------------')\n",
    "        print(\"\\n\",classification_report(true_labels_org.ravel(),pred_labels_org.ravel()))\n",
    "        print({'road': 0, 'parking': 1, 'drivable fallback': 2, 'sidewalk': 3, 'rail track': 4, 'non-drivable fallback': 5, 'person': 6, 'animal': 7, 'rider': 8, 'motorcycle': 9, 'bicycle': 10, 'autorickshaw': 11, 'car': 12, 'truck': 13, 'bus': 14, 'caravan': 15, 'trailer': 16, 'train': 17, 'vehicle fallback': 18, 'curb': 19, 'wall': 20, 'fence': 21, 'guard rail': 22, 'billboard': 23, 'traffic sign': 24, 'traffic light': 25})\n",
    "    \n",
    "    return \n",
    "\n",
    "def Load_For_Prediction(String):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to Load Serialized preprocessed Data of Train, Val and Test based on choice for Prediction\n",
    "    Input  : String <String>\n",
    "    Return : prep_train_img_files_save <X>, prep_train_label_files_save <Y> \"\"\"\n",
    "\n",
    "    global prep_train_img_files_save, prep_train_label_files_save\n",
    "\n",
    "    if String ==\"Train_data\":\n",
    "        prep_train_img_files_save=joblib.load(root + \"IDD_Segmentation/prep_train_img_files_save_80\")\n",
    "        prep_train_label_files_save=joblib.load(root + \"IDD_Segmentation/prep_train_label_files_save_80\")    \n",
    "    elif String ==\"Val_data\":\n",
    "        prep_train_img_files_save=joblib.load(root+\"IDD_Segmentation/prep_val_img_files_save\")\n",
    "        prep_train_label_files_save=joblib.load(root+\"IDD_Segmentation/prep_val_label_files_save1\")\n",
    "    elif String ==\"Test_data\":\n",
    "        prep_train_img_files_save=joblib.load(root + \"IDD_Segmentation/prep_test_img_files_save_20\")\n",
    "        prep_train_label_files_save=joblib.load(root + \"IDD_Segmentation/prep_test_label_files_save_20\")\n",
    "    elif String == \"Subset\":\n",
    "        prep_train_img_files_save=joblib.load(root + \"hi_img\")\n",
    "        prep_train_label_files_save=joblib.load(root + \"hi\")\n",
    "    else:\n",
    "        raise Exception(\"Enter one of the string\\n'Train_data' or 'Val_data' or 'Test_data'\")\n",
    "    \n",
    "    return prep_train_img_files_save, prep_train_label_files_save\n",
    "\n",
    "def plot_training_result(out):\n",
    "\n",
    "    ''' Function to plot Epoch vs Crossentropy and Epoch vs MIOU graph after Traning of a Model ''' \n",
    "\n",
    "    # Sub_plot with two figures\n",
    "    figure, loc_ind = plt.subplots(1, 2,figsize=(15,5))\n",
    "\n",
    "    # Obtain values to plot \n",
    "    miou, val_miou= out.history['miou'], out.history['val_miou']\n",
    "    loss, val_loss= out.history['loss'], out.history['val_loss']\n",
    "\n",
    "    # epoch list\n",
    "    num_epochs = list(range(1,len(miou)+1))\n",
    "\n",
    "    # ploting Epoch vs Crossentropy Loss    \n",
    "    loc_ind[0].plot(num_epochs,loss,'r',label='train loss',linewidth=1.25)\n",
    "    loc_ind[0].plot(num_epochs,val_loss,'g',label='validation loss',linewidth=1.25)\n",
    "    loc_ind[0].set_ylabel('Categorical Crossentropy Loss',fontsize=14)\n",
    "    loc_ind[0].set_xlabel('Epoch',fontsize=14)\n",
    "    loc_ind[0].set_title('Epoch vs Crossentropy Loss',fontsize=16)\n",
    "    loc_ind[0].grid()\n",
    "    loc_ind[0].legend()\n",
    "\n",
    "    # Epoch vs Mean Intersection over union\n",
    "    loc_ind[1].plot(num_epochs,miou,linestyle='--',marker='o',color=\"deeppink\",label='train miou',linewidth=1.25)\n",
    "    loc_ind[1].plot(num_epochs,val_miou,linestyle='--',marker='o',color=\"dodgerblue\",label='val miou',linewidth=1.25)\n",
    "    loc_ind[1].set_ylabel('Mean Intersection over union',fontsize=14)\n",
    "    loc_ind[1].set_xlabel('Epoch',fontsize=14)\n",
    "    loc_ind[1].set_title('Epoch vs Mean Intersection over union',fontsize=16)\n",
    "    loc_ind[1].grid()\n",
    "    loc_ind[1].legend()\n",
    "    plt.tight_layout(pad=3.0)\n",
    "    plt.show() \n",
    "\n",
    "def color_code(le_pred):\n",
    "\n",
    "    \"\"\" \n",
    "    Function to Color Code given Label Mask using RGB-Color to make it suitable to Display  \n",
    "    Input  : le_pred <2D_Array>\n",
    "    Return : col_pred <3d_Array>   \"\"\"\n",
    "    \n",
    "    col_pred = moveaxis(np.repeat(le_pred[:, :, np.newaxis], 3, axis=2), -1, 0)\n",
    "    # print(col_pred)\n",
    "    color_code = [\n",
    "    [128, 64, 128], [72, 98, 91], [255, 204, 54], [220, 20, 60], [147, 114, 178],\n",
    "    [132, 91, 83], [70, 70, 70], [105, 143, 35], [255, 69, 0], [0, 191, 255],\n",
    "    [128, 0, 128], [255, 165, 0], [255, 0, 0], [0, 255, 0], [0, 0, 255],\n",
    "    [255, 255, 0], [0, 255, 255], [255, 0, 255], [192, 192, 192], [255, 192, 203],\n",
    "    [75, 0, 130], [255, 99, 71], [100, 149, 237], [255, 140, 0], [0, 255, 127],\n",
    "    [255, 20, 147], [0, 250, 154]\n",
    "]\n",
    "         \n",
    "    m, n= col_pred.shape[1], col_pred.shape[2]\n",
    "    for k in range(3):\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                index=7 if int(col_pred[k][i][j])==255 else int(col_pred[k][i][j])\n",
    "                col_pred[k][i][j]=color_code[index][k]\n",
    "    col_pred=np.moveaxis(col_pred, 0, -1)\n",
    "    return col_pred\n",
    "\n",
    "\n",
    "def image_prepare(data,batch_files,Model):\n",
    "    \n",
    "    '''Read and preprocess images to generete batch of images for prediction'''\n",
    "    \n",
    "    height,width,n_classes,image=Model.input_shape[1],480,26,[]\n",
    "    for img_i in range(len(batch_files)):\n",
    "        img = cv2.imread(data+batch_files[img_i])\n",
    "        img = cv2.resize(img,(width,height))\n",
    "        img = np.float32(img)/255\n",
    "        image.append(img)\n",
    "    image=np.array(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def image_prepare_j(slice_saved,Model):\n",
    "    '''Function to get samples batch wise from saved data for Prediction'''\n",
    "    return np.array(slice_saved)\n",
    "\n",
    "\n",
    "def label_prepare_j(slice_saved,Model):\n",
    "    \n",
    "    '''Function to get Mask batch wise from saved data for Prediction'''\n",
    "    \n",
    "    height,width,n_classes=Model.input_shape[1], 480, 26\n",
    "    ar=np.empty((len(slice_saved),n_classes,height,width), dtype=np.uint8)\n",
    "    for j in range(len(slice_saved)):\n",
    "        for i in range(n_classes):\n",
    "            ar[j][i]=slice_saved[j][i].todense()\n",
    "    ar = moveaxis(ar, 1, 3)\n",
    "    return ar\n",
    "\n",
    "\n",
    "def label_prepare(data,batch_files,Model):\n",
    "    \n",
    "    '''Read and preprocess Label Mask to generete batch of Labels for prediction'''\n",
    "    \n",
    "    height,width,n_classes,labels=Model.input_shape[1],480,26,[]\n",
    "    for i in range(len(batch_files)):\n",
    "        label = np.zeros((height, width, n_classes)).astype(np.uint8)\n",
    "        img = cv2.imread(data+batch_files[i])\n",
    "        img = cv2.resize(img,(width,height))\n",
    "        img1 = img[:,:,0]\n",
    "        for i in range(n_classes):\n",
    "            label[:,:,i] = (img1==i).astype(np.uint8)\n",
    "        labels.append(label)\n",
    "    labels=np.array(labels)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def prob_to_label(cf_matrix, Accuracy, predictions, label=False):\n",
    "    \n",
    "    ''' Function to get Actual Labels from Predicted probabilities to compute confusion matrix and Accuracy '''\n",
    "\n",
    "    pred_Out,true_Out,pred_labels,true_labels=[],[],[],[]\n",
    "    predictions = moveaxis(predictions[np.newaxis,:, :,:] if (len(predictions.shape)==3) else predictions, 3, 1)\n",
    "    if isinstance(label,np.ndarray):label = moveaxis(label[np.newaxis,:, :,:] if (len(label.shape)==3) else label, 3, 1)\n",
    "    \n",
    "    for p_index in range(predictions.shape[0]):\n",
    "\n",
    "        p1 = np.where(predictions[p_index]<0.5, predictions[p_index], 1)# if a[ijk]>=0.5 then a[ijk]=1 (False)\n",
    "        p1 = np.where(p1==1, p1, 0).astype(int)\n",
    "        w = np.argmax(p1, axis=0).astype(int) # 248*480 matrix with 1-6\n",
    "        \n",
    "        if isinstance(label,np.ndarray):\n",
    "\n",
    "            p2= np.where(label[p_index]==1, label[p_index], 0)\n",
    "            v = np.argmax(label[p_index], axis=0).astype(int)   # 224*480  \n",
    "            Accuracy.append(np.round(accuracy_score(v.ravel(), w.ravel()),4))\n",
    "\n",
    "            cf_matrix=np.add(cf_matrix, confusion_matrix(v.ravel(), w.ravel(),labels=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]))\n",
    "            true_labels.append(v),true_Out.append(p2)          \n",
    "        \n",
    "        pred_labels.append(w),pred_Out.append(p1)\n",
    "    \n",
    "    if isinstance(label,np.ndarray):true_Out=moveaxis(np.array(true_Out), 1, 3)\n",
    "    pred_Out=moveaxis(np.array(pred_Out), 1, 3)\n",
    "    \n",
    "    return pred_Out, pred_labels, true_Out, true_labels, cf_matrix, Accuracy\n",
    "\n",
    "\n",
    "def Intersect_over_union(y_val, y_pred, Mean_MIoU):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to compute Intersect_Over_Union for given set of Samples Inputs \n",
    "    Input  : y_val <4D_Array>, y_pred <4D_Array>, Mean_MIoU <List>\n",
    "    Return : Mean_MIoU <List>      \"\"\" \n",
    "\n",
    "    for index in range(y_pred.shape[0]):\n",
    "\n",
    "        class_iou ,n_classes=[],26\n",
    "        y_predi = np.argmax(y_pred[index], axis=2) \n",
    "        y_truei = np.argmax(y_val[index], axis=2)\n",
    "        \n",
    "        for c in range(n_classes):\n",
    "            TP = np.sum((y_truei == c) & (y_predi == c))\n",
    "            FP = np.sum((y_truei != c) & (y_predi == c))\n",
    "            FN = np.sum((y_truei == c) & (y_predi != c)) \n",
    "            IoU = TP / (TP + FP + FN) if (TP + FP + FN)>0 else 0\n",
    "            class_iou.append(IoU)\n",
    "        \n",
    "        MIoU=sum(class_iou)/n_classes\n",
    "        Mean_MIoU.append(MIoU)\n",
    "    \n",
    "    return Mean_MIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Function_1(path_i,Mean_MIoU=None,cf_matrix=None,Accuracy=None,Model=None,load=True,Read_from_File=True,plot=True,path_l=0,plot_limit=2):\n",
    "\n",
    "    '''\n",
    "    ----------------------------------------------------------------------------\n",
    "    The Function contains the entire Deep Learning pipeline \n",
    "    Function predicts the output for given raw input\n",
    "\n",
    "    1. Reading Image data files from a specified directory.\n",
    "    2. Preprocessing Images by Resizing and Normalization.\n",
    "    3. Preparation of Data to make it suitable for prediction.\n",
    "    4. Deep learning Model Prediction for prepared input.\n",
    "    5. Finally Plotting of the predicted image segmentation.  \n",
    "    ----------------------------------------------------------------------------\n",
    "        Parameters\n",
    "        ----------\n",
    "        path_i <string>                 : Absolute Path of images Data files\n",
    "        Read_from_File <Boolean>        : Indicator to specify input format\n",
    "        plot_limit <Int>                : Plot limit of segmentaion output\n",
    "        Model <Int>                     : Model Choice for prediction\n",
    "        Other Parameters\t            : **kwargs other properties\n",
    "    \n",
    "        returns \n",
    "        --------\n",
    "        Output Arguments             : Output values\n",
    "    ----------------------------------------------------------------------------\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Image resolution and classes\n",
    "    height, width, n_classes = 224, 480, 7\n",
    "    \n",
    "    # Load selected Deep Learning model\n",
    "    if load: Model = Select_Model()\n",
    "    \n",
    "    # Function to predict Batch wise to avoid run out of memory\n",
    "    def Predict_Segment(i,data,lab,pb_size,Mean_MIoU,cf_matrix,Accuracy):\n",
    "        \n",
    "        '''  Function to perform prediction for a given subset of Data at a time  '''\n",
    "        \n",
    "        # Get index offset for data \n",
    "        s, e = i, min(i+pb_size,len(data))        \n",
    "        \n",
    "        if Read_from_File == True: # Image Data preparation\n",
    "            test_images = image_prepare(path_i,data[s:e],Model)\n",
    "            y_true = label_prepare(path_l,lab[s:e],Model) if isinstance(path_l, str) else [0]   #decompress sparce\n",
    "        else:\n",
    "            test_images = image_prepare_j(data[s:e],Model)\n",
    "            y_true = label_prepare_j(lab[s:e],Model) if isinstance(path_l, list) else [0]\n",
    "        \n",
    "        # Model Prediction \n",
    "        y_pred = Model.predict(test_images)  \n",
    "        \n",
    "        # Get Actual Labels from Predicted probabilities and compute some metrics if label is avaliable\n",
    "        pred_Out,pred_labels,true_Out,true_labels,cf_matrix,Accuracy = prob_to_label(cf_matrix,Accuracy,y_pred,y_true)\n",
    "        if isinstance(path_l, str) or isinstance(path_l, list):\n",
    "            Mean_MIoU = Intersect_over_union(np.array(true_Out),np.array(pred_Out),Mean_MIoU)\n",
    "\n",
    "        if plot: # ploting Few Segmentation Samples from prediction \n",
    "          if ((i==0) or ((pb_size==1) and i<plot_limit)):\n",
    "            if (i==0):print(\"\\nFew Segmentation Samples:>>>\\n\")\n",
    "            plot_segmentation(test_images,pred_labels,true_labels,plot_limit) \n",
    "        \n",
    "        return pred_Out, true_Out,pred_labels,true_labels,cf_matrix,Mean_MIoU,Accuracy\n",
    "    \n",
    "    if Read_from_File: # Reading all Data files from specified Path \n",
    "        data = sorted(os.listdir(path_i))\n",
    "        lab = sorted(os.listdir(path_l)) if (isinstance(path_l, str) or isinstance(path_l, list)) else 0\n",
    "    else:\n",
    "        data, lab = path_i,path_l if (isinstance(path_l, str) or isinstance(path_l, list)) else 0\n",
    "    \n",
    "    # Computing subset size for samples for prediction \n",
    "    pb_size=1 if (len(data)<plot_limit) or Model.name==\"SEGNET\" else plot_limit\n",
    "    Pred_org,y_true_org,pred_labels_org,true_labels_org = [],[],[],[]\n",
    "\n",
    "    # Invoke Predict_Segment() for prediction for many subset of Samples\n",
    "    for i in range(0,len(data),pb_size):\n",
    "        dat = Predict_Segment(i,data,lab,pb_size,Mean_MIoU,cf_matrix,Accuracy)\n",
    "        Pred_org.extend(dat[0]),y_true_org.extend(dat[1])\n",
    "        pred_labels_org.extend(dat[2]),true_labels_org.extend(dat[3])\n",
    "        cf_matrix = dat[4]\n",
    "    \n",
    "    return np.array(pred_labels_org,dtype=np.uint8),np.array(true_labels_org,dtype=np.uint8),dat[4],dat[5],dat[6]\n",
    "\n",
    "def Function_2(path_img,path_lab,Mean_MIoU=None,cf_matrix=None,Accuracy=None,Model=None,plot=True,Read_from_File=True,load=True,cr=True,plot_limit=2):\n",
    "    \n",
    "    '''\n",
    "    ---------------------------------------------------------------------------------------\n",
    "    The Function implements the entire Deep Learning pipeline where it accepts \n",
    "    Images and Labels to predict output and calculates segmentation  metrics\n",
    "\n",
    "    1. Accept Images and Labels data as input from the directory\n",
    "    2. perform Preprocessing and Data Preparation\n",
    "    3. Model Prediction for prepared Data as input\n",
    "    4. Performance Calculation using multiple metics\n",
    "    5. Finally printing and Plotting of the prediction results\n",
    "    ---------------------------------------------------------------------------------------\n",
    "        Parameters\n",
    "        ----------\n",
    "        path_img, path_lab <string>                    : Absolute Path of Images and labels.\n",
    "        Read_from_File <Boolean>                       : Indicator to specify input format\n",
    "        Mean_MIoU, cf_matrix, Accuracy <metrics>       : Variables to store prediction Scores\n",
    "        plot_limit <Int>                               : Plot limit of segmentaion output\n",
    "        Model <Int>                                    : Model Choice for prediction\n",
    "        Other Parameters\t                           : **kwargs other properties\n",
    "\n",
    "        returns \n",
    "        --------\n",
    "        Mean_MIoU, cf_matrix, Accuracy                 : resulting Performance Metrics\n",
    "    ----------------------------------------------------------------------------------------\n",
    "\n",
    "    '''\n",
    "\n",
    "    # perform prediction by calling function1 \n",
    "    pred_labels_org,true_labels_org,cf_matrix,Mean_MIoU,Accuracy = Function_1(path_img,Mean_MIoU,cf_matrix,Accuracy,Model,load,Read_from_File,plot,path_lab,plot_limit)\n",
    "    \n",
    "    # printing prediction result\n",
    "    if plot: Print_result(Mean_MIoU,cf_matrix,Accuracy,true_labels_org,pred_labels_org,cr)\n",
    "    \n",
    "    return Mean_MIoU, cf_matrix, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook,tqdm\n",
    "def predict_for(data_for_prediction, weights_save_path=False):\n",
    "    \n",
    "    \"\"\"  General Function to perform prediction for the specified data split  \"\"\"\n",
    "    \n",
    "    Mean_MIoU, Accuracy, cf_matrix=[], [], np.zeros((26,26))\n",
    "    x, y = Load_For_Prediction(data_for_prediction)\n",
    "    Model, Skip = Select_Model(weights_save_path), 2\n",
    "    \n",
    "    for d in tqdm_notebook(range(0,len(x),Skip)):\n",
    "\n",
    "        if (d>=(len(x)-Skip)): \n",
    "            plot,_,_=True,clear_output(),print(\"Total number of samples in {0} : {1}\".format(data_for_prediction,len(x)))\n",
    "        else: plot=False\n",
    "        \n",
    "        Miou, cf_matrix, Accuracy=Function_2(x[d:d+Skip],y[d:d+Skip],Mean_MIoU,cf_matrix,Accuracy,Model,plot,False,False,False)\n",
    "    collected = gc.collect()\n",
    "    \n",
    "    return Miou, Accuracy, cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from segmentation_models import Unet\n",
    "# from segmentation_models import get_preprocessing\n",
    "# from segmentation_models.losses import bce_jaccard_loss\n",
    "# from segmentation_models.metrics import iou_score\n",
    "\n",
    "# BACKBONE = 'efficientnetb7'\n",
    "# ENCODER_WEIGHTS = 'imagenet'\n",
    "# CLASSES = ['road', 'parking', 'drivable fallback', 'sidewalk', 'rail track', 'non-drivable fallback', 'person', 'animal', 'rider', 'motorcycle', 'bicycle', 'autorickshaw', 'car', 'truck', 'bus', 'caravan', 'trailer', 'train', 'vehicle fallback', 'curb', 'wall', 'fence', 'guard rail', 'billboard', 'traffic sign', 'traffic light', 'pole', 'polegroup', 'obs-str-bar-fallback', 'building', 'bridge', 'tunnel', 'vegetation', 'sky', 'fallback background', 'unlabeled']\n",
    "# DEVICE = 'cuda'\n",
    "\n",
    "# # create segmentation model with pretrained encoder\n",
    "# preprocessing_fn = get_preprocessing(BACKBONE)\n",
    "# model = Unet(BACKBONE, encoder_weights='imagenet', classes=len(CLASSES))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\r\n",
      "Version: 2.13.1\r\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\r\n",
      "Home-page: https://www.tensorflow.org/\r\n",
      "Author: Google Inc.\r\n",
      "Author-email: packages@tensorflow.org\r\n",
      "License: Apache 2.0\r\n",
      "Location: /home/ram/.local/lib/python3.8/site-packages\r\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "! pip show tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with imagenet pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 15:06:05.987826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3336 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:18:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 15:06:42.295356: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "batch_size, epochs = 2, 50\n",
    "model = sm.Unet('efficientnetb7',encoder_weights='imagenet',classes=26,input_shape=(224, 480,3),activation='softmax')\n",
    "# model.summary()\n",
    "tensorboard, filepath = TensorBoard(log_dir=root+\"logs/unet_img_efficientnetb7_nlrr{}\".format(str(time())[:10])),model_root+\"Unet_imgnet_efficientnetb7_nlrr.hdf5\"\n",
    "steps_per_epoch,validation_steps=int((len(train_img_files1))/batch_size),int((len(val_img_files1))/batch_size)\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(0.0001), loss = 'categorical_crossentropy',metrics = ['accuracy',miou])\n",
    "es = EarlyStopping(monitor='val_miou', mode='max', verbose=1, patience=5)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_miou', verbose=2, save_best_only=True, mode='max')\n",
    "history_tf=model.fit_generator(train_batch_generator(batch_size,epochs), steps_per_epoch=steps_per_epoch, epochs=epochs, verbose=1, validation_data=val_batch_generator(batch_size,epochs),\n",
    "                            validation_steps=validation_steps, callbacks=[checkpoint,es,tensorboard])\n",
    "print(\"--- %s seconds ---\" % (time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_training_result(history_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miou, Accuracy, cf_matrix = predict_for(\"Train_data\",\"EffUNet38.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Miou, Accuracy, cf_matrix = predict_for(\"Val_data\",\"EffUNet38.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Miou, Accuracy, cf_matrix = predict_for(\"Test_data\",\"EffUNet38.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for Subset data of 50 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Miou, Accuracy, cf_matrix = predict_for(\"Subset\",\"EffUNet38.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore from here, only for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_code(le_pred):\n",
    "\n",
    "    \"\"\" \n",
    "    Function to Color Code given Label Mask using RGB-Color to make it suitable to Display  \n",
    "    Input  : le_pred <2D_Array>\n",
    "    Return : col_pred <3d_Array>   \"\"\"\n",
    "    \n",
    "    col_pred = moveaxis(np.repeat(le_pred[:, :, np.newaxis], 3, axis=2), -1, 0)\n",
    "    # print(col_pred)\n",
    "    color_code = [\n",
    "    [128, 64, 128], [72, 98, 91], [255, 204, 54], [220, 20, 60], [147, 114, 178],\n",
    "    [132, 91, 83], [70, 70, 70], [105, 143, 35], [255, 69, 0], [0, 191, 255],\n",
    "    [128, 0, 128], [255, 165, 0], [255, 0, 0], [0, 255, 0], [0, 0, 255],\n",
    "    [255, 255, 0], [0, 255, 255], [255, 0, 255], [192, 192, 192], [255, 192, 203],\n",
    "    [75, 0, 130], [255, 99, 71], [100, 149, 237], [255, 140, 0], [0, 255, 127],\n",
    "    [255, 20, 147], [0, 250, 154]\n",
    "]\n",
    "         \n",
    "    m, n= col_pred.shape[1], col_pred.shape[2]\n",
    "    for k in range(3):\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                index=7 if int(col_pred[k][i][j])==255 else int(col_pred[k][i][j])\n",
    "                col_pred[k][i][j]=color_code[index][k]\n",
    "    col_pred=np.moveaxis(col_pred, 0, -1)\n",
    "    return col_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing color coding and visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Color_code_label(label_image, sns_code=False):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Function to color code a given Label Mask\n",
    "#     input  : Mask<Array>,  Boolean(Indicator of color scheme)\n",
    "#     return : color coded Mask <Array>\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Switch axis of Mask\n",
    "#     cf_label_image=np.moveaxis(label_image, -1, 0)\n",
    "#     # cmap = plt.get_cmap('tab10')\n",
    "#     # colors = cmap(np.linspace(0, 1, 256))\n",
    "#     # preparing color mappings\n",
    "#     color_code = [\n",
    "#     [128, 64, 128], [72, 98, 91], [255, 204, 54], [220, 20, 60], [147, 114, 178],\n",
    "#     [132, 91, 83], [70, 70, 70], [105, 143, 35], [255, 69, 0], [0, 191, 255],\n",
    "#     [128, 0, 128], [255, 165, 0], [255, 0, 0], [0, 255, 0], [0, 0, 255],\n",
    "#     [255, 255, 0], [0, 255, 255], [255, 0, 255], [192, 192, 192], [255, 192, 203],\n",
    "#     [75, 0, 130], [255, 99, 71], [100, 149, 237], [255, 140, 0], [0, 255, 127],\n",
    "#     [255, 20, 147], [0, 250, 154]\n",
    "# ]\n",
    "#     # print(len(color_code))\n",
    "    \n",
    "#     # change value in each pixel to a specific color \n",
    "#     m, n= cf_label_image.shape[1], cf_label_image.shape[2]\n",
    "#     for k in range(3):\n",
    "#         for i in range(m):\n",
    "#             for j in range(n):\n",
    "#                 index=26 if int(cf_label_image[k][i][j])==255 else int(cf_label_image[k][i][j])\n",
    "#                 cf_label_image[k][i][j]=color_code[index][k]\n",
    "    \n",
    "#     # Switch back axis of color-coded Mask\n",
    "#     cf_label_image=np.moveaxis(cf_label_image, 0, -1)\n",
    "#     return cf_label_image\n",
    "\n",
    "# visualize a color-coded Mask \n",
    "# plot_mask=Get_image(root + \"IDD_Segmentation/gtFine/train_label_level3/train_label_level3_30_733588_gtFine_labellevel3Ids.png\")\n",
    "# print(plot_mask.shape)\n",
    "# cf_label_image=Color_code_label(plot_mask)\n",
    "# plt.figure(figsize=(9.6, 6.8))\n",
    "# plt.title(\"Color Coded Mask\")\n",
    "# plt.imshow(cf_label_image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing labels level of masks and intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Get and plot label mask\n",
    "# plt.figure(figsize=(9.6, 6.8))\n",
    "# Label_Mask=Get_images('C:/Users/sasan/OneDrive/Desktop/FYP/idd-segmentation/testing/',True)\n",
    "# plt.imshow(Label_Mask, cmap='gray')\n",
    "# plt.title(\"Label Mask\")\n",
    "# plt.show()\n",
    "# print(\"Label Mask Shape:\",Label_Mask.shape)\n",
    "\n",
    "# # compute Value Count of each pixel\n",
    "# Label_Mask=[i for i in Label_Mask.ravel() if i != 255]\n",
    "# (unique, counts) = np.unique(Label_Mask, return_counts=True)\n",
    "# Value_count= dict(zip(unique, counts))\n",
    "# print(\"\\nUnique Class Labels in Mask:\",set(Label_Mask))\n",
    "# print(\"\\nClass Value Count:\",Value_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test subset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Subset image creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# import cv2\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def Prepare_Image_and_Save(path, name, img_files):\n",
    "#     height, width = 224, 480\n",
    "#     image = []\n",
    "#     for j in range(len(path)):\n",
    "#         for i in tqdm(range(len(img_files[j]))):\n",
    "#             print(path[j] + img_files[j][i])\n",
    "#             img = cv2.imread(path[j] + img_files[j][i])\n",
    "#             img = cv2.resize(img, (width, height))\n",
    "#             img = np.float32(img) / 255\n",
    "#             image.append(img)\n",
    "#     print(len(image))\n",
    "#     joblib.dump(image, name)\n",
    "#     return True\n",
    "\n",
    "# path1 = [root+'sample_test_img/']\n",
    "# train_img_files1=sorted(os.listdir(root+'sample_test_img/'))\n",
    "\n",
    "# img_files1 = [train_img_files1]\n",
    "\n",
    "# Indicator1 = Prepare_Image_and_Save(path1,root+'hi_img',img_files1)\n",
    "# if Indicator1: print(\"Data Preparation of Images Successful Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Subset label creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "def Prepare_Label_and_Save(path, n_classes, name):\n",
    "    sparse_list = []\n",
    "    for k in range(len(path)):\n",
    "        files = sorted(os.listdir(path[k]))\n",
    "        height, width, n_classes = 224, 480, n_classes\n",
    "        for j in tqdm(range(len(files))):\n",
    "            label = np.zeros((n_classes, height, width), dtype=np.uint8)\n",
    "            img = cv2.imread(path[k] + \"/\" + files[j], cv2.IMREAD_GRAYSCALE)\n",
    "            img1 = cv2.resize(img, (width, height))\n",
    "            for i in range(n_classes):\n",
    "                label[i, :, :] = (img1 == i).astype(np.uint8)\n",
    "            sp_list = []\n",
    "            for i in range(label.shape[0]):\n",
    "                sp_list.append(csc_matrix(label[i]))\n",
    "            sparse_list.append(sp_list)\n",
    "    joblib.dump(sparse_list, name)\n",
    "    return True\n",
    "\n",
    "\n",
    "path1 = [root+'/sample_test_labels']\n",
    "\n",
    "Indicator=Prepare_Label_and_Save(path1,26,root+\"hi\")\n",
    "if Indicator: print(\"Data Preparation of Labels Successful Done!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
